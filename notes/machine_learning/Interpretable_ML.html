<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Interpretable ML</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-interactiveBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-translucentGray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="aa2ef3fd-8f7c-45cb-976a-8b1d25b7063b" class="page mono"><header><img class="page-cover-image" src="Interpretable%20ML%20aa2ef3fd8f7c45cb976a8b1d25b7063b/Interpretable_ML.png" style="object-position:center 76.94%"/><div class="page-header-icon page-header-icon-with-cover"><img class="icon" src="https://www.notion.so/icons/document_gray.svg"/></div><h1 class="page-title">Interpretable ML</h1><p class="page-description"></p><table class="properties"><tbody><tr class="property-row property-row-select"><th><span class="icon property-icon"><img src="https://www.notion.so/icons/categories_gray.svg" style="width:14px;height:14px"/></span>Category</th><td><span class="selected-value select-value-color-purple">Machine Learning</span></td></tr><tr class="property-row property-row-multi_select"><th><span class="icon property-icon"><img src="https://www.notion.so/icons/tag_gray.svg" style="width:14px;height:14px"/></span>Tag</th><td><span class="selected-value select-value-color-red">Interpretable ML</span></td></tr><tr class="property-row property-row-relation"><th><span class="icon property-icon"><img src="https://www.notion.so/icons/link_gray.svg" style="width:14px;height:14px"/></span>參考文獻</th><td><a href="https://www.notion.so/Interpretable-ML-4567c5e10d0240aaa0c233fa94141aed?pvs=21"><img class="icon" src="https://www.notion.so/icons/link_gray.svg"/>Interpretable ML</a></td></tr></tbody></table></header><div class="page-body"><h2 id="d71b94ed-a0ad-4714-9c19-729f20a3a38d" class="">基本介紹</h2><h3 id="2a9058bd-06db-4e6a-ba9f-0cd769e77182" class="">黑箱模型與白箱模型</h3><ul id="9b32eec7-841a-4d2e-a3bd-7dd7c5d8d44c" class="bulleted-list"><li style="list-style-type:disc"><strong>Black Box Model：</strong>黑盒模型是只無法解釋模型內部的運作方式的模型（例如類神經網絡）。</li></ul><ul id="408d21c2-7972-4962-afc8-eed5f4128aa0" class="bulleted-list"><li style="list-style-type:disc"><strong>White Box Model：</strong>白盒模型又被稱為可解釋模型，顧名思義就是指可以理解預測過程的模型。<p id="7f5cc417-c8f1-48a0-9ae0-2160927c60e3" class="">
</p></li></ul><h3 id="95d15c65-e929-49a9-a991-47b0b15c9055" class=""><strong>Interpretable &amp; Explainable</strong></h3><ul id="35a773ee-3b06-4037-8932-aaa87aa31a13" class="bulleted-list"><li style="list-style-type:disc"><strong>Interpretable：</strong>指模型<strong><mark class="highlight-yellow_background">不是黑箱</mark></strong><strong>，</strong>我們可以容易知道它的內容。</li></ul><ul id="3c707ac9-acc5-4744-8318-48f7850dace0" class="bulleted-list"><li style="list-style-type:disc"><strong>Explainable：</strong>指模型<strong><mark class="highlight-yellow_background">原本是黑箱</mark></strong>，我們想辦法賦予它解釋的能力。</li></ul><p id="26d1fbbc-ff50-404b-ac1a-65f0bc0f809d" class="">
</p><h2 id="4a325997-50a1-4d23-9e98-57865d508972" class="">可解釋性</h2><h3 id="3cc823ad-2890-4523-a6ac-c45474a4a87c" class=""><strong>可解釋性的兩種定義</strong></h3><ul id="335ba051-76d7-4d05-ba6c-0226798515c3" class="bulleted-list"><li style="list-style-type:disc">Interpretability is the degree to which a human can understand the cause of a decision.
（可解釋性是指人類能夠理解決策原因的程度。）</li></ul><ul id="51916ede-bc0c-46c9-b16f-52ebe3cc4876" class="bulleted-list"><li style="list-style-type:disc">Interpretability is the degree to which a human can consistently predict the model’s result.
（可解釋性是指人類能夠一致地預測模型結果的程度。）</li></ul><p id="387520bf-6264-4a0e-8183-58d9fd2a2cac" class="">
</p><h3 id="4ea8c9ff-eaf8-4e8c-a591-97475759cefc" class="">可解釋的重要性</h3><p id="7a5d03dc-adfc-4c5c-8849-5db8c90ec4cd" class="">通常人對於機器預測出來的結果都抱著懷疑的態度的，所以知道機器為什麼會得出這個結果的原因就很重要，知道原因就可以去分析這個預測過程的邏輯有沒有問題，例如：今天在醫療診斷上，機器為什麼診斷出這個病症的原因就非常重要，因為人命關天如果誤診的話後果很嚴重，所以我們需要對模型的可解釋性來提高社會的接受度。</p><p id="d29d1103-fc8c-4709-88d0-7039cf5a7001" class="">
</p><p id="b10fa6b3-f7fc-4742-96c9-8564afd19ae4" class="">如果可以確保機器學習模型是可解釋的，我們就可以更容易的確認以下幾點：</p><ul id="eee4c159-657f-4ec4-bfc5-570daa69da50" class="bulleted-list"><li style="list-style-type:disc"><strong>公平（Fairness）：</strong>確保預測沒有偏見，不會隱含或明確歧視代表性不足的群體。</li></ul><ul id="2a9c5699-b7bc-4a48-9a01-2e735c590490" class="bulleted-list"><li style="list-style-type:disc"><strong>隱私（Privacy）：</strong>確保數據中的敏感信息受到保護。</li></ul><ul id="d2909e20-b236-45e0-ae35-62353433e0ff" class="bulleted-list"><li style="list-style-type:disc"><strong>可靠性或穩健性（Reliability or Robustness）：</strong>確保輸入中的小變化不會導致預測發生大的變化。</li></ul><ul id="8d3ec1a1-e61c-4216-b152-440edfb48170" class="bulleted-list"><li style="list-style-type:disc"><strong>因果關係（Causality）：</strong>檢查是否只提取因果關係。</li></ul><ul id="914eda19-3040-4843-b5e9-2459d401aa4a" class="bulleted-list"><li style="list-style-type:disc"><strong>信任（Trust）：</strong>與黑匣子相比，人類更容易信任解釋其決策的系統。</li></ul><p id="6e885284-f06b-48b7-92f1-b47f28df1269" class="">
</p><h3 id="5f28947d-c6fc-406c-b188-b83ff3acdaec" class="">可解釋性方法分類</h3><p id="85fc5818-29d3-422d-ba30-299888de78b9" class="">機器學習可解釋性的方法可以根據以下標準進行分類：</p><ul id="5c4bd506-8cf8-454e-9af1-9c7ed95fad9a" class="toggle"><li><details open=""><summary><strong>固有的還是事後的？</strong></summary><ul id="dd7bf4c8-577c-42cd-8cd3-fb9e552adf9c" class="bulleted-list"><li style="list-style-type:disc"><strong>固有的（Intrinsic）：</strong>固有的解釋性指的是由於其簡單結構而被認為是可解釋的機器學習模型，例如短決策樹或稀疏線性模型。</li></ul><ul id="270ba412-46ae-48b3-a760-f8d11a0eb3e0" class="bulleted-list"><li style="list-style-type:disc"><strong>事後的（Post Hoc）：</strong>事後的解釋性指的是在模型訓練之後應用解釋方法。例如，排列特徵重要性是一種事後的解釋方法，事後的方法也可以應用於固有的可解釋的模型。例如，可以計算決策樹的排列特徵重要性。 </li></ul><p id="6826ad83-6ed1-4ffa-8a60-0cc3cd56c98e" class="">
</p></details></li></ul><ul id="ccd98922-a559-44c9-b880-970af2b751e7" class="toggle"><li><details open=""><summary><strong>模型特定還是模型無關？</strong></summary><ul id="464b8778-aadb-4645-a5e5-5693938ce6f6" class="bulleted-list"><li style="list-style-type:disc"><strong>模型特定（Model-specific）：</strong>局限於特定的模型類別。例如，線性模型中的迴歸權重的解釋是模型特定的解釋，因為按定義，內在可解釋模型的解釋始終是模型特定的，只適用於例如神經網絡解釋的工具是模型特定的。</li></ul><ul id="c915c238-52d2-4562-83f5-a82574e1eb58" class="bulleted-list"><li style="list-style-type:disc"><strong>模型無關（Model-agnostic）：</strong>可以用於任何機器學習模型，並在模型訓練之後應用。這些不可知方法通常通過分析特徵輸入和輸出對來工作。按照定義，這些方法不能訪問模型內部，例如權重或結構信息。</li></ul><p id="3328a4c4-6190-4af1-9c11-78d922645ca2" class="">
</p></details></li></ul><ul id="dec2a9c5-c8aa-4e0d-be9b-b7d6fa4ac6ae" class="toggle"><li><details open=""><summary><strong>局部還是全域？</strong></summary><ul id="730ec4e9-46db-4678-bbe8-edf9c34b8ac4" class="bulleted-list"><li style="list-style-type:disc"><strong>局部（Local）：</strong>根據某一個輸入樣本進行回答。例如：給模型一張圖片，模型判斷是一只貓，問模型為什麼覺得這張圖片是一只貓。</li></ul><ul id="8c113164-d862-449d-82b9-6eaed6676cb3" class="bulleted-list"><li style="list-style-type:disc"><strong>全域（Global）：</strong>根據模型參數本身分析原因。例如：並未給模型任何特定圖片，對具有一堆參數的模型而言，什麼樣的東西叫作一只貓。</li></ul></details></li></ul><p id="ce38da24-cec5-4398-b16b-6e6b9492f03e" class="">
</p><h3 id="3df9b5f3-ad7f-40d0-b197-373bc9cdec94" class="">可解釋性範圍</h3><ul id="fe9a684a-d22a-4911-a363-594799b57232" class="toggle"><li><details open=""><summary><strong>演算法的透明度</strong></summary><p id="46bf1196-751f-48cc-9c61-109ecbdc77d0" class="">演算法透明度（Algorithm Transparency）是指理解演算法如何從資料中學習模型以及它可以學習什麼樣的關係。例如，如果使用卷積神經網絡對圖像進行分類，可以解釋該演算法在最底層學習邊緣檢測器和濾鏡。</p><p id="6a2223fb-8bb9-4d88-a71e-7ef7271c17a0" class="">
</p></details></li></ul><ul id="3daf844a-2e70-4fc6-b79a-d0e17437a0c3" class="toggle"><li><details open=""><summary><strong>全域模型的可解釋性</strong></summary><p id="6df6d32a-5b8b-46dc-bc4c-e9920f1d9696" class="">全域模型的可解釋性是了解模型如何根據特徵和每個學習到的組件（例如權重、其他參數和結構）做出決策，哪些特徵是重要的，它們之間發生了什麼樣的互動，全域模型可解釋性有助於理解基於特徵的目標結果的分佈情況。實際上，全域模型可解釋性非常難以實現。任何超過少數幾個參數或權重的模型都不太可能符合平均人類的短期記憶。</p><p id="3761d7b8-a931-48c8-8e37-d30c161b8dea" class="">
</p></details></li></ul><ul id="0162bc6c-6d04-4e44-a3a3-b3fc922be1a6" class="toggle"><li><details open=""><summary><strong>模組化的全域可解釋性</strong></summary><p id="01399c69-7b44-4977-8378-c5e67646cc8b" class="">要去記住模型的所有權種並且去估計每個特徵的重要性與對模型預測的影響是幾乎不可能做到的事，所以通過將機器學習模型分解成多個模組，並且對每個模組進行解釋，從而實現對整個模型的全域解釋。</p><p id="d0212026-4fc4-42c9-b994-2cfda87bd274" class="">
</p></details></li></ul><ul id="acaa8901-cc37-4f83-86ef-d0488b570bd6" class="toggle"><li><details open=""><summary><strong>單體預測的局部可解釋性</strong></summary><p id="17813dd3-23d3-4054-a5ac-a956ab642506" class="">單個預測的局部可解釋性是指指對於<strong><mark class="highlight-yellow_background">單個樣本的預測結果</mark></strong>，通過解釋模型對於這個預測的貢獻，從而理解模型對這個預測的決策過程和原因。例如我們正在使用一個機器學習模型來預測某個人是否會買一輛新車，如果模型預測該人會買車，我們可能希望知道是什麼因素導致了這個預測結果，而單體預測的局部可解釋性方法可以幫助我們解釋這個預測結果。</p><p id="0de85696-5e55-45c4-9064-743c5250d4ef" class="">
</p></details></li></ul><ul id="cee5e7cb-fa05-4f73-8871-7904933977fd" class="toggle"><li><details open=""><summary><strong>群體預測的局部可解釋性</strong></summary><p id="8f80f9c0-ebea-46e1-b655-9f3127bcd709" class="">群體預測的局部可解釋性是指對於<strong><mark class="highlight-yellow_background">一組樣本的預測結果</mark></strong>，能夠解釋這些預測結果是如何由模型產生的。例如我們正在使用一個機器學習模型來預測一個產品的銷售量，並且我們有一個包含多個產品的數據集。如果我們想知道模型是如何產生這些預測結果的，群體預測的局部可解釋性方法可以幫助我們解釋這些預測結果。</p></details></li></ul><p id="e86ccf71-a088-4085-9f21-223bd91373a1" class="">
</p><h3 id="8f85bb1b-4bfa-4286-ac79-8e6cd078f98d" class="">可解釋性的評估</h3><ul id="be9f6c56-01d5-48dc-831e-23861564b4cc" class="toggle"><li><details open=""><summary><strong>應用層面評估（真實任務）</strong></summary><p id="b1235cfa-71de-4805-b093-4d3bbbcb37c6" class="">應用層面評估是將機器學習模型應用於實際問題中，從應用的角度對模型進行評估。例如，將模型應用於文本分類或圖像分類等任務，並對其在真實場景中的表現進行評估。</p><p id="1b8ddbe1-002e-4385-bea8-f5614d3e890f" class="">
</p></details></li></ul><ul id="bcbaadfe-9229-4c23-8d12-0087e23017d9" class="toggle"><li><details open=""><summary><strong>人類層面評估（簡單任務）</strong></summary><p id="8d4fcbe7-4854-4891-8c86-75a2b9144753" class="">人類層面評估是通過與人類表現進行比較，來評估機器學習模型的性能。例如，在圖像識別中，可以邀請人類參與識別，然後比較機器學習模型的識別結果與人類表現的差異。</p><p id="d56e72a0-17ee-4c12-a266-7a10bc40c5cd" class="">
</p></details></li></ul><ul id="be63978a-4574-432c-9de8-0cc31d8b6295" class="toggle"><li><details open=""><summary><strong>功能層面評估（代理任務）</strong></summary><p id="c6e71bee-e9bb-44b7-bdd3-eac008e11d59" class="">功能層面評估通常會對模型的訓練過程進行分析，從而確定模型是否具有可解釋性和可重現性。例如，在深度學習中，可以對模型的損失函數和梯度進行分析，以確定模型是否具有良好的訓練效果和收斂性。</p></details></li></ul><p id="99e2c594-32c0-4772-a71b-5f267644b611" class="">
</p><h3 id="9b956db6-ff60-4d0e-b210-a4486aa16b19" class=""><strong>解釋的性質</strong></h3><p id="fd815cc7-f8db-45b8-9863-1ce538539353" class="">一個解釋通常以人能理解的方式關聯一個實例的特徵值和模型預測結果。</p><ul id="bcaf8355-b688-4a75-a0f6-d36c49bafe75" class="toggle"><li><details open=""><summary><strong>解釋方法的性質</strong></summary><ul id="8ced4114-6030-4659-9041-9c9416e55b17" class="bulleted-list"><li style="list-style-type:disc"><strong>表達能力（Expressive Power）：</strong>表達能力是該方法能夠生成的解釋的<strong><mark class="highlight-yellow_background">語言</mark></strong>或<strong><mark class="highlight-yellow_background">結構</mark></strong>，一種解釋方法可以生成 IF-THEN 規則、決策樹、加權和、自然語言或其他東西。</li></ul><ul id="1015f824-10c0-463f-a1ea-ad71fdf2ed31" class="bulleted-list"><li style="list-style-type:disc"><strong>半透明度（Translucency）：</strong>半透明度是指解釋方法在有多依賴於該機器學習的模型。例如：依賴於本質上可解釋模型（如線性迴歸模型）的解釋方法是高透明度，反之僅依靠操縱輸入和觀察預測的方法具有低透明度，高透明度的優點是該方法可以依賴更多訊息來生成解釋，低透明度的好處是解釋方法更好的可移植性。</li></ul><ul id="87ba42ab-c7a6-42fc-9f38-3fddc0146769" class="bulleted-list"><li style="list-style-type:disc"><strong>可移植性（Portability）：</strong>可移植性是指此解釋方法可以輕鬆地從一個環境移植到另一個環境。</li></ul><ul id="1bf7a80e-35ce-4a04-b582-596a12465e4b" class="bulleted-list"><li style="list-style-type:disc"><strong>算法複雜度（Algorithmic Complexity）：</strong>描述了生成解釋的方法的計算複雜度，當計算時間成為生成解釋的瓶頸時，需要考慮此屬性。</li></ul><p id="3059f345-1f28-49ff-8c02-23f022b0c452" class="">
</p></details></li></ul><ul id="48f4da61-3a93-48ab-a79f-ac446789e70d" class="toggle"><li><details open=""><summary><strong>個別解釋的性質</strong></summary><ul id="5accebd0-0ccd-455c-b560-8c4a56b925f9" class="bulleted-list"><li style="list-style-type:disc"><strong>準確性（Accuracy）：</strong>個別解釋的準確性是指解釋對未見數據的預測有多準確，這是一個特別重要的屬性，因為如果解釋的準確度低於機器學習模型，那它就失去解釋的價值，但是如果機器學習模型的準確性也很低，並且目標是解釋黑盒模型的作用，那麼低準確性也可以，在這種情況下，只有保真度很重要。</li></ul><ul id="8b0ad40a-cd15-4099-b9c3-1261cd149503" class="bulleted-list"><li style="list-style-type:disc"><strong>保真度（Fidelity）：</strong>保真度是指解釋近似於黑盒模型的預測的程度，保真度是解釋最重要的屬性之一，因為保真度低的解釋對於模型來說是沒有用的，準確性和保真度密切相關，如果黑盒模型準確率高，解釋保真度高，那麼解釋也準確率高。</li></ul><ul id="ffee281b-8068-4755-8529-2d7944128f3c" class="bulleted-list"><li style="list-style-type:disc"><strong>一致性（Consistency）：</strong>一致性是指在相同任務上訓練的模型之間解釋的不同程度，高一致性對於真正依賴相似關係的模型是可取的。</li></ul><ul id="83213004-8098-4226-b91e-0b8b64394f50" class="bulleted-list"><li style="list-style-type:disc"><strong>穩定性（Stability）：</strong>穩定性比較的是相同模型下相似實例之間的解釋相似程度，穩定性高表示特徵略微變化不會大幅改變解釋，穩定性差可能是解釋方法方差異很大導致的。</li></ul><ul id="0a229619-90c9-4e6b-92d5-38e6f77431fd" class="bulleted-list"><li style="list-style-type:disc"><strong>可理解性（Comprehensibility）：</strong>可理解性就是指人類是否能夠理解此解釋，測量可理解性的想法包括測量解釋的大小（線性模型中具有非零權重的特徵的數量、決策規則的數量…等）或測試人們如何從解釋中預測機器學習模型的行為，還應考慮解釋中使用的特徵的可理解性，特徵的複雜轉換可能比原始特徵更難理解。</li></ul><ul id="380f6f08-eff8-437d-b663-7a70a7917215" class="bulleted-list"><li style="list-style-type:disc"><strong>確定性（Certainty）：</strong>確定性是指解釋是否反映了機器學習模型的確定性？許多機器學習模型只給出預測，而沒有說明模型對預測正確性的可信度。如果模型預測一名患者患癌症的概率為 4%，那麼它是否與具有不同特徵值的另一名患者患癌症的概率為 4% 一樣確定？包含模型確定性的解釋非常有用。</li></ul><ul id="3dabee6c-e384-48b3-a928-bef799f3d316" class="bulleted-list"><li style="list-style-type:disc"><strong>重要性程度（Degree of Importance）：</strong>解釋如何很好地反映特徵或部分解釋的重要性？例如，如果生成決策規則作為對單個預測的解釋，是否清楚規則的哪個條件最重要？</li></ul><ul id="ed7365af-9be0-4a6e-9546-0759aa72db26" class="bulleted-list"><li style="list-style-type:disc"><strong>新穎性（Novelty）：</strong>解釋是否反映了要解釋的數據實例是否來自遠離訓練數據分佈的“新”區域？在這種情況下，模型可能不准確，解釋也可能毫無用處。新穎性的概念與確定性的概念相關。新穎性越高，模型越有可能由於缺乏數據而具有低確定性。</li></ul><ul id="4843ff0d-d55c-495a-b573-cd8b260e3b52" class="bulleted-list"><li style="list-style-type:disc"><strong>代表性（Representativeness）：</strong>一個解釋涵蓋了多少個實例？解釋可以涵蓋整個模型（例如線性迴歸模型中權重的解釋）或僅代表單個預測（例如Shapley值）。</li></ul></details></li></ul><p id="aeaa714a-b1fe-476d-90ad-12af08f5acdd" class="">
</p><h3 id="4e075b30-85be-426d-bff2-bc1bd677cab4" class="">人性化的解釋</h3><p id="90bf5899-0144-453a-83aa-cf8187955471" class="">解釋的主要目的就是能夠得到一個相信機器的理由，而只要這個理由是可以被使用者接受的，那這個解釋就是一個好的解釋。</p><p id="b1748faf-819e-4c61-839d-7dd56bd2e516" class="">
</p><h2 id="aa6ea00c-c879-49b4-a098-4271ef42b0ab" class="">可解釋模型</h2><ul id="d2e64bee-124f-458a-bbc5-19ace11e3373" class="bulleted-list"><li style="list-style-type:disc"><strong>線性的（Linear）：</strong>特徵和目標之間的關聯是線性建模。</li></ul><ul id="c8c95c45-41d7-46ea-b07a-a7b18bacd600" class="bulleted-list"><li style="list-style-type:disc"><strong>單調性（Monotone）：</strong>可確保特徵與目標結果之間的關係在特徵的整個範圍內始終沿同一方向發展：特徵值的增加總是導致目標值增加或總是減少結果，單調性對於模型的解釋很有用，因為它更容易理解關係。</li></ul><ul id="fc5191a6-bc85-43bf-b153-dd50326ca6e1" class="bulleted-list"><li style="list-style-type:disc"><strong>相互作用（Interaction）：</strong>一些模型可以自動包含特徵之間的相互作用以預測目標結果。您可以通過手動創建交互特徵將交互包含在任何類型的模型中，交互可以提高預測性能，但太多或太複雜的交互會損害可解釋性。</li></ul><table id="79ed0ee2-5ccf-4c8c-8ccc-4c8b17d19a91" class="simple-table"><thead class="simple-table-header"><tr id="0d216f87-3ca9-4e47-b485-31654d6f6269"><th id="sfQ}" class="simple-table-header-color simple-table-header" style="width:161.1875px"><strong>演算法</strong></th><th id="CHGl" class="simple-table-header-color simple-table-header" style="width:135.2px"><strong>線性的</strong></th><th id="gZqV" class="simple-table-header-color simple-table-header" style="width:135.2px"><strong>單調性</strong></th><th id="Mybf" class="simple-table-header-color simple-table-header" style="width:135.2px"><strong>相互作用</strong></th><th id="N`v~" class="simple-table-header-color simple-table-header" style="width:135.2px"><strong>任務</strong></th></tr></thead><tbody><tr id="09cddef4-07ae-4557-a7ed-60b85a6e4f4f"><td id="sfQ}" class="" style="width:161.1875px"><a href="https://www.notion.so/Linear-Regression-7f2c661038a449cf85b1cb3d5cd8480d?pvs=21">Linear Regression</a></td><td id="CHGl" class="" style="width:135.2px">是</td><td id="gZqV" class="" style="width:135.2px">是</td><td id="Mybf" class="" style="width:135.2px">否</td><td id="N`v~" class="" style="width:135.2px">迴歸</td></tr><tr id="1e2d9f2d-3ebb-4af9-a8a1-f509719894d0"><td id="sfQ}" class="" style="width:161.1875px"><a href="https://www.notion.so/Logistic-Regression-077b6916029e4c089925de1375cc86c5?pvs=21">Logistic Regression</a></td><td id="CHGl" class="" style="width:135.2px">否</td><td id="gZqV" class="" style="width:135.2px">是</td><td id="Mybf" class="" style="width:135.2px">否</td><td id="N`v~" class="" style="width:135.2px">分類</td></tr><tr id="3bd988cd-ec10-4760-8fc6-9025454f4002"><td id="sfQ}" class="" style="width:161.1875px"><a href="https://www.notion.so/Decision-Tree-0742157a98644648b01f690167605b20?pvs=21">Decision Tree</a></td><td id="CHGl" class="" style="width:135.2px">否</td><td id="gZqV" class="" style="width:135.2px">部分</td><td id="Mybf" class="" style="width:135.2px">是</td><td id="N`v~" class="" style="width:135.2px">分類、迴歸</td></tr><tr id="d9c1fd6c-25f0-4edf-9f36-867457d7f496"><td id="sfQ}" class="" style="width:161.1875px">RuleFit</td><td id="CHGl" class="" style="width:135.2px">是</td><td id="gZqV" class="" style="width:135.2px">否</td><td id="Mybf" class="" style="width:135.2px">是</td><td id="N`v~" class="" style="width:135.2px">分類、迴歸</td></tr><tr id="064fdca1-c9fd-46ca-8980-2aafe4ea073c"><td id="sfQ}" class="" style="width:161.1875px"><a href="https://www.notion.so/Naive-Bayes-0e4f693dfe5945feb94028fb96909fba?pvs=21">Naive Bayes</a></td><td id="CHGl" class="" style="width:135.2px">否</td><td id="gZqV" class="" style="width:135.2px">是</td><td id="Mybf" class="" style="width:135.2px">否</td><td id="N`v~" class="" style="width:135.2px">分類</td></tr><tr id="6d2b26ce-67cd-4372-b296-7e2353ab0d21"><td id="sfQ}" class="" style="width:161.1875px"><a href="https://www.notion.so/KNN-69bc8d8d5c3a4f979d10ea783166cc30?pvs=21">KNN</a></td><td id="CHGl" class="" style="width:135.2px">否</td><td id="gZqV" class="" style="width:135.2px">否</td><td id="Mybf" class="" style="width:135.2px">否</td><td id="N`v~" class="" style="width:135.2px">分類、迴歸</td></tr></tbody></table><p id="cbb5ca56-2a9c-4f36-89d5-3b193923017f" class="">
</p><h3 id="ae83b3f6-65ae-4dc8-9c92-d717c93b3a60" class=""><strong>Linear Regression</strong></h3><p id="4a3e5cbb-a0af-48f2-8472-77aba6f76356" class="">線性迴歸模型將目標預測為特徵輸入的加權和，線性迴歸模型的最大優勢是線性：它使估計過程變得簡單，最重要的是，這些線性方程在模塊級別（即權重）上具有易於理解的解釋。這是線性模型和所有類似模型在醫學、社會學、心理學和許多其他定量研究領域等學術領域如此廣泛的主要原因之一。例如，在醫學領域，不僅要預測患者的臨床結果，還要量化藥物的影響，同時以可解釋的方式考慮性別、年齡等特徵。</p><p id="0407aba6-5e5b-40ed-96b1-b774db25cf3d" class="">
</p></div></article></body></html>